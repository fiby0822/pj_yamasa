#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""æ”¹å–„çµæœã‚µãƒãƒªãƒ¼ã‚’S3ã«ä¿å­˜"""

import boto3
import os
import json
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

def save_improvement_summary():
    # æ”¹å–„çµæœãƒ‡ãƒ¼ã‚¿
    improvement_data = {
        "timestamp": datetime.now().isoformat(),
        "new_features_added": [
            "is_business_day_f",
            "is_friday_f",
            "dow_month_interaction_f",
            "is_weekly_milestone_f",
            "week_to_date_mean_f",
            "material_dow_mean_f"
        ],
        "total_features": {
            "before": 113,
            "after": 119
        },
        "model_metrics": {
            "rmse": {
                "before": 19.35,
                "after": 19.15
            },
            "mae": {
                "before": 2.64,
                "after": 2.59
            }
        },
        "error_statistics": {
            "mean_error_rate": {
                "before": 965.96,
                "after": 715.97,
                "improvement": 965.96 - 715.97
            },
            "median_error_rate": {
                "before": 224.47,
                "after": 144.00,
                "improvement": 224.47 - 144.00
            }
        },
        "accuracy_distribution": {
            "within_20_percent": {
                "before_count": 89,
                "before_ratio": 17.8,
                "after_count": 104,
                "after_ratio": 20.8,
                "improvement_count": 104 - 89,
                "improvement_ratio": 20.8 - 17.8
            },
            "within_30_percent": {
                "before_count": 115,
                "before_ratio": 23.0,
                "after_count": 137,
                "after_ratio": 27.4,
                "improvement_count": 137 - 115,
                "improvement_ratio": 27.4 - 23.0
            },
            "within_50_percent": {
                "before_count": 150,
                "before_ratio": 30.0,
                "after_count": 178,
                "after_ratio": 35.6,
                "improvement_count": 178 - 150,
                "improvement_ratio": 35.6 - 30.0
            }
        },
        "most_important_feature": "material_dow_mean_f",
        "total_material_keys_analyzed": 500
    }

    # S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š
    s3 = boto3.client('s3',
                      aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),
                      aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),
                      region_name=os.getenv('AWS_DEFAULT_REGION', 'ap-northeast-1'))

    bucket_name = "fiby-yamasa-prediction"
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    date_dir = datetime.now().strftime('%Y%m%d')

    # JSONã¨ã—ã¦ä¿å­˜
    json_content = json.dumps(improvement_data, ensure_ascii=False, indent=2)

    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒãƒ¼ã‚¸ãƒ§ãƒ³
    key = f"models/{date_dir}/improvement_summary_{timestamp}.json"
    s3.put_object(
        Bucket=bucket_name,
        Key=key,
        Body=json_content,
        ContentType='application/json'
    )
    print(f"æ”¹å–„ã‚µãƒãƒªãƒ¼ä¿å­˜: s3://{bucket_name}/{key}")

    # æœ€æ–°ç‰ˆã¨ã—ã¦ä¿å­˜
    key_latest = "models/improvement_summary_latest.json"
    s3.put_object(
        Bucket=bucket_name,
        Key=key_latest,
        Body=json_content,
        ContentType='application/json'
    )
    print(f"æœ€æ–°æ”¹å–„ã‚µãƒãƒªãƒ¼ä¿å­˜: s3://{bucket_name}/{key_latest}")

    # æ”¹å–„çµæœã‚’è¦‹ã‚„ã™ãè¡¨ç¤º
    print("\n" + "="*60)
    print("ğŸ“Š äºˆæ¸¬ç²¾åº¦æ”¹å–„çµæœã‚µãƒãƒªãƒ¼")
    print("="*60)
    print("\nã€è¿½åŠ ã—ãŸç‰¹å¾´é‡ã€‘")
    for feature in improvement_data["new_features_added"]:
        print(f"  - {feature}")

    print("\nã€ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®æ”¹å–„ã€‘")
    print(f"  RMSE: {improvement_data['model_metrics']['rmse']['before']:.2f} â†’ {improvement_data['model_metrics']['rmse']['after']:.2f}")
    print(f"  MAE: {improvement_data['model_metrics']['mae']['before']:.2f} â†’ {improvement_data['model_metrics']['mae']['after']:.2f}")

    print("\nã€äºˆæ¸¬èª¤å·®ã®æ”¹å–„ã€‘")
    print(f"  å¹³å‡èª¤å·®ç‡: {improvement_data['error_statistics']['mean_error_rate']['before']:.2f}% â†’ {improvement_data['error_statistics']['mean_error_rate']['after']:.2f}% (æ”¹å–„: -{improvement_data['error_statistics']['mean_error_rate']['improvement']:.2f}%)")
    print(f"  ä¸­å¤®èª¤å·®ç‡: {improvement_data['error_statistics']['median_error_rate']['before']:.2f}% â†’ {improvement_data['error_statistics']['median_error_rate']['after']:.2f}% (æ”¹å–„: -{improvement_data['error_statistics']['median_error_rate']['improvement']:.2f}%)")

    print("\nã€äºˆæ¸¬ç²¾åº¦åˆ†å¸ƒã®æ”¹å–„ã€‘")
    for threshold, data in improvement_data["accuracy_distribution"].items():
        threshold_label = threshold.replace("within_", "").replace("_percent", "%ä»¥å†…")
        print(f"  {threshold_label}: {data['before_count']}å€‹ ({data['before_ratio']:.1f}%) â†’ {data['after_count']}å€‹ ({data['after_ratio']:.1f}%) (æ”¹å–„: +{data['improvement_count']}å€‹, +{data['improvement_ratio']:.1f}%)")

    print("\nã€æœ€é‡è¦ç‰¹å¾´é‡ã€‘")
    print(f"  {improvement_data['most_important_feature']}")
    print("="*60)

if __name__ == "__main__":
    save_improvement_summary()